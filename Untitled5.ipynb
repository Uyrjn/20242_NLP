{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c58b60db-e553-4ec5-8e54-d774f95c92d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model và tokenizer đã được load thành công!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "# 1. Giải nén\n",
    "zip_path = 'model.zip'\n",
    "extract_dir = './saved_model'\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "# 2. Load model và tokenizer từ thư mục đã giải nén\n",
    "from transformers import BertForTokenClassification, BertTokenizerFast\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(extract_dir)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(extract_dir)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model và tokenizer đã được load thành công!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e2dae2-ef25-4eae-b033-285f89cd9dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: All the appetizers and salads were fabulous, the steak was mouth watering and the pasta was delicious!!!\n",
      "Ground Truth Aspects: ['appetizers']\n",
      "Predicted Aspects: ['appetizers', 'salads', 'steak', 'pasta']\n",
      "--------------------------------------------------\n",
      "Sentence: All the appetizers and salads were fabulous, the steak was mouth watering and the pasta was delicious!!!\n",
      "Ground Truth Aspects: ['salads']\n",
      "Predicted Aspects: ['appetizers', 'salads', 'steak', 'pasta']\n",
      "--------------------------------------------------\n",
      "Sentence: All the appetizers and salads were fabulous, the steak was mouth watering and the pasta was delicious!!!\n",
      "Ground Truth Aspects: ['steak']\n",
      "Predicted Aspects: ['appetizers', 'salads', 'steak', 'pasta']\n",
      "--------------------------------------------------\n",
      "Sentence: All the appetizers and salads were fabulous, the steak was mouth watering and the pasta was delicious!!!\n",
      "Ground Truth Aspects: ['pasta']\n",
      "Predicted Aspects: ['appetizers', 'salads', 'steak', 'pasta']\n",
      "--------------------------------------------------\n",
      "Sentence: And really large portions.\n",
      "Ground Truth Aspects: ['portions']\n",
      "Predicted Aspects: []\n",
      "--------------------------------------------------\n",
      "Sentence: The sweet lassi was excellent as was the lamb chettinad and the garlic naan but the rasamalai was forgettable.\n",
      "Ground Truth Aspects: ['sweet lassi']\n",
      "Predicted Aspects: ['sweet lassi', 'lamb chettinad', 'garlic naan', 'rasamalai']\n",
      "--------------------------------------------------\n",
      "Sentence: The sweet lassi was excellent as was the lamb chettinad and the garlic naan but the rasamalai was forgettable.\n",
      "Ground Truth Aspects: ['lamb chettinad']\n",
      "Predicted Aspects: ['sweet lassi', 'lamb chettinad', 'garlic naan', 'rasamalai']\n",
      "--------------------------------------------------\n",
      "Sentence: The sweet lassi was excellent as was the lamb chettinad and the garlic naan but the rasamalai was forgettable.\n",
      "Ground Truth Aspects: ['garlic naan']\n",
      "Predicted Aspects: ['sweet lassi', 'lamb chettinad', 'garlic naan', 'rasamalai']\n",
      "--------------------------------------------------\n",
      "Sentence: The sweet lassi was excellent as was the lamb chettinad and the garlic naan but the rasamalai was forgettable.\n",
      "Ground Truth Aspects: ['rasamalai']\n",
      "Predicted Aspects: ['sweet lassi', 'lamb chettinad', 'garlic naan', 'rasamalai']\n",
      "--------------------------------------------------\n",
      "Sentence: Service was quick.\n",
      "Ground Truth Aspects: ['Service']\n",
      "Predicted Aspects: ['service']\n",
      "--------------------------------------------------\n",
      "Sentence: Oh, don't even let me start with how expensive the bills were!\n",
      "Ground Truth Aspects: ['bills']\n",
      "Predicted Aspects: ['bills']\n",
      "--------------------------------------------------\n",
      "Sentence: Service is top notch.\n",
      "Ground Truth Aspects: ['Service']\n",
      "Predicted Aspects: ['service']\n",
      "--------------------------------------------------\n",
      "Sentence: The best thing I tasted were the lambc hops.\n",
      "Ground Truth Aspects: ['lambc hops']\n",
      "Predicted Aspects: []\n",
      "--------------------------------------------------\n",
      "Sentence: Even though its good seafood, the prices are too high.\n",
      "Ground Truth Aspects: ['seafood']\n",
      "Predicted Aspects: ['seafood', 'prices']\n",
      "--------------------------------------------------\n",
      "Sentence: Even though its good seafood, the prices are too high.\n",
      "Ground Truth Aspects: ['prices']\n",
      "Predicted Aspects: ['seafood', 'prices']\n",
      "--------------------------------------------------\n",
      "Sentence: In addition, the food is very good and the prices are reasonable.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['food', 'prices']\n",
      "--------------------------------------------------\n",
      "Sentence: In addition, the food is very good and the prices are reasonable.\n",
      "Ground Truth Aspects: ['prices']\n",
      "Predicted Aspects: ['food', 'prices']\n",
      "--------------------------------------------------\n",
      "Sentence: The food is great and authentic.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['food']\n",
      "--------------------------------------------------\n",
      "Sentence: I recommend the garlic shrimp, okra (bindi), and anything with lamb.\n",
      "Ground Truth Aspects: ['garlic shrimp']\n",
      "Predicted Aspects: ['garlic shrimp', 'okra']\n",
      "--------------------------------------------------\n",
      "Sentence: I recommend the garlic shrimp, okra (bindi), and anything with lamb.\n",
      "Ground Truth Aspects: ['okra (bindi)']\n",
      "Predicted Aspects: ['garlic shrimp', 'okra']\n",
      "--------------------------------------------------\n",
      "Sentence: I recommend the garlic shrimp, okra (bindi), and anything with lamb.\n",
      "Ground Truth Aspects: ['lamb']\n",
      "Predicted Aspects: ['garlic shrimp', 'okra']\n",
      "--------------------------------------------------\n",
      "Sentence: The menu was impressive with selections ranging from a burger, to steak, to escargot.\n",
      "Ground Truth Aspects: ['menu']\n",
      "Predicted Aspects: ['menu']\n",
      "--------------------------------------------------\n",
      "Sentence: The menu was impressive with selections ranging from a burger, to steak, to escargot.\n",
      "Ground Truth Aspects: ['burger']\n",
      "Predicted Aspects: ['menu']\n",
      "--------------------------------------------------\n",
      "Sentence: The menu was impressive with selections ranging from a burger, to steak, to escargot.\n",
      "Ground Truth Aspects: ['steak']\n",
      "Predicted Aspects: ['menu']\n",
      "--------------------------------------------------\n",
      "Sentence: The menu was impressive with selections ranging from a burger, to steak, to escargot.\n",
      "Ground Truth Aspects: ['escargot']\n",
      "Predicted Aspects: ['menu']\n",
      "--------------------------------------------------\n",
      "Sentence: very good breads as well.\n",
      "Ground Truth Aspects: ['breads']\n",
      "Predicted Aspects: ['breads']\n",
      "--------------------------------------------------\n",
      "Sentence: Anyway, the food is good, the price is right and they have a decent wine list.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['food', 'price']\n",
      "--------------------------------------------------\n",
      "Sentence: Anyway, the food is good, the price is right and they have a decent wine list.\n",
      "Ground Truth Aspects: ['price']\n",
      "Predicted Aspects: ['food', 'price']\n",
      "--------------------------------------------------\n",
      "Sentence: Anyway, the food is good, the price is right and they have a decent wine list.\n",
      "Ground Truth Aspects: ['wine list']\n",
      "Predicted Aspects: ['food', 'price']\n",
      "--------------------------------------------------\n",
      "Sentence: The food was lousy -too sweet or too salty and the portions tiny.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['food', 'portions']\n",
      "--------------------------------------------------\n",
      "Sentence: The food was lousy -too sweet or too salty and the portions tiny.\n",
      "Ground Truth Aspects: ['portions']\n",
      "Predicted Aspects: ['food', 'portions']\n",
      "--------------------------------------------------\n",
      "Sentence: But the coconut rice was good.\n",
      "Ground Truth Aspects: ['coconut rice']\n",
      "Predicted Aspects: ['coconut rice']\n",
      "--------------------------------------------------\n",
      "Sentence: And the Tom Kha soup was pathetic.\n",
      "Ground Truth Aspects: ['Tom Kha soup']\n",
      "Predicted Aspects: ['tom kha soup']\n",
      "--------------------------------------------------\n",
      "Sentence: The food now is inconsistent.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['food']\n",
      "--------------------------------------------------\n",
      "Sentence: Try the crunchy tuna, it is to die for.\n",
      "Ground Truth Aspects: ['crunchy tuna']\n",
      "Predicted Aspects: ['tuna']\n",
      "--------------------------------------------------\n",
      "Sentence: Reasonable prices.\n",
      "Ground Truth Aspects: ['prices']\n",
      "Predicted Aspects: []\n",
      "--------------------------------------------------\n",
      "Sentence: Add to that great service and great food at a reasonable price and you have yourself the beginning of a great evening.\n",
      "Ground Truth Aspects: ['service']\n",
      "Predicted Aspects: ['service', 'food']\n",
      "--------------------------------------------------\n",
      "Sentence: Add to that great service and great food at a reasonable price and you have yourself the beginning of a great evening.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['service', 'food']\n",
      "--------------------------------------------------\n",
      "Sentence: Add to that great service and great food at a reasonable price and you have yourself the beginning of a great evening.\n",
      "Ground Truth Aspects: ['price']\n",
      "Predicted Aspects: ['service', 'food']\n",
      "--------------------------------------------------\n",
      "Sentence: Unfortunately, the food was NOT something to get worked up about.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['food']\n",
      "--------------------------------------------------\n",
      "Sentence: The food is great and reasonably priced.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['food']\n",
      "--------------------------------------------------\n",
      "Sentence: The food is great and reasonably priced.\n",
      "Ground Truth Aspects: ['priced']\n",
      "Predicted Aspects: ['food']\n",
      "--------------------------------------------------\n",
      "Sentence: Their calzones are horrific, bad, vomit-inducing, YUCK.\n",
      "Ground Truth Aspects: ['calzones']\n",
      "Predicted Aspects: ['calzones']\n",
      "--------------------------------------------------\n",
      "Sentence: A few tips: skip the turnip cake, roast pork buns and egg custards.\n",
      "Ground Truth Aspects: ['turnip cake']\n",
      "Predicted Aspects: []\n",
      "--------------------------------------------------\n",
      "Sentence: A few tips: skip the turnip cake, roast pork buns and egg custards.\n",
      "Ground Truth Aspects: ['roast pork buns']\n",
      "Predicted Aspects: []\n",
      "--------------------------------------------------\n",
      "Sentence: A few tips: skip the turnip cake, roast pork buns and egg custards.\n",
      "Ground Truth Aspects: ['egg custards']\n",
      "Predicted Aspects: []\n",
      "--------------------------------------------------\n",
      "Sentence: The bagels are fabulous.\n",
      "Ground Truth Aspects: ['bagels']\n",
      "Predicted Aspects: ['bagels']\n",
      "--------------------------------------------------\n",
      "Sentence: While the ambiance and atmosphere were great, the food and service could have been a lot better.\n",
      "Ground Truth Aspects: ['ambiance']\n",
      "Predicted Aspects: ['am', 'biance', 'atmosphere', 'food', 'service']\n",
      "--------------------------------------------------\n",
      "Sentence: While the ambiance and atmosphere were great, the food and service could have been a lot better.\n",
      "Ground Truth Aspects: ['atmosphere']\n",
      "Predicted Aspects: ['am', 'biance', 'atmosphere', 'food', 'service']\n",
      "--------------------------------------------------\n",
      "Sentence: While the ambiance and atmosphere were great, the food and service could have been a lot better.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['am', 'biance', 'atmosphere', 'food', 'service']\n",
      "--------------------------------------------------\n",
      "Sentence: While the ambiance and atmosphere were great, the food and service could have been a lot better.\n",
      "Ground Truth Aspects: ['service']\n",
      "Predicted Aspects: ['am', 'biance', 'atmosphere', 'food', 'service']\n",
      "--------------------------------------------------\n",
      "Sentence: Our waitress was sweet and accomodating, not overbearing.\n",
      "Ground Truth Aspects: ['waitress']\n",
      "Predicted Aspects: ['waitress']\n",
      "--------------------------------------------------\n",
      "Sentence: My goodness, everything from the fish to the rice to the seaweed was absolutely amazing.\n",
      "Ground Truth Aspects: ['fish']\n",
      "Predicted Aspects: ['fish', 'rice', 'seaweed']\n",
      "--------------------------------------------------\n",
      "Sentence: My goodness, everything from the fish to the rice to the seaweed was absolutely amazing.\n",
      "Ground Truth Aspects: ['rice']\n",
      "Predicted Aspects: ['fish', 'rice', 'seaweed']\n",
      "--------------------------------------------------\n",
      "Sentence: My goodness, everything from the fish to the rice to the seaweed was absolutely amazing.\n",
      "Ground Truth Aspects: ['seaweed']\n",
      "Predicted Aspects: ['fish', 'rice', 'seaweed']\n",
      "--------------------------------------------------\n",
      "Sentence: Good spreads, great beverage selections and bagels really tasty.\n",
      "Ground Truth Aspects: ['spreads']\n",
      "Predicted Aspects: ['beverage selections', 'bagels']\n",
      "--------------------------------------------------\n",
      "Sentence: Good spreads, great beverage selections and bagels really tasty.\n",
      "Ground Truth Aspects: ['beverage selections']\n",
      "Predicted Aspects: ['beverage selections', 'bagels']\n",
      "--------------------------------------------------\n",
      "Sentence: Good spreads, great beverage selections and bagels really tasty.\n",
      "Ground Truth Aspects: ['bagels']\n",
      "Predicted Aspects: ['beverage selections', 'bagels']\n",
      "--------------------------------------------------\n",
      "Sentence: The food options rule.\n",
      "Ground Truth Aspects: ['food options']\n",
      "Predicted Aspects: ['food options']\n",
      "--------------------------------------------------\n",
      "Sentence: Consistently good Japanese Tapas.\n",
      "Ground Truth Aspects: ['Japanese Tapas']\n",
      "Predicted Aspects: []\n",
      "--------------------------------------------------\n",
      "Sentence: The sushi was awful!\n",
      "Ground Truth Aspects: ['sushi']\n",
      "Predicted Aspects: ['sushi']\n",
      "--------------------------------------------------\n",
      "Sentence: The food was great.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['food']\n",
      "--------------------------------------------------\n",
      "Sentence: With the theater 2 blocks away we had a delicious meal in a beautiful room.\n",
      "Ground Truth Aspects: ['meal']\n",
      "Predicted Aspects: ['theater', 'meal']\n",
      "--------------------------------------------------\n",
      "Sentence: With the theater 2 blocks away we had a delicious meal in a beautiful room.\n",
      "Ground Truth Aspects: ['room']\n",
      "Predicted Aspects: ['theater', 'meal']\n",
      "--------------------------------------------------\n",
      "Sentence: I love the fact that the pizza tastes so good and is so cheap.\n",
      "Ground Truth Aspects: ['pizza']\n",
      "Predicted Aspects: ['pizza']\n",
      "--------------------------------------------------\n",
      "Sentence: Service was prompt, friendly and great.\n",
      "Ground Truth Aspects: ['Service']\n",
      "Predicted Aspects: ['service']\n",
      "--------------------------------------------------\n",
      "Sentence: I haven't eat a lamb chop as delicious as that, the salads are really nice dressed with lemon and extra virgnin olive oil.\n",
      "Ground Truth Aspects: ['lamb chop']\n",
      "Predicted Aspects: ['lamb chop', 'salads']\n",
      "--------------------------------------------------\n",
      "Sentence: I haven't eat a lamb chop as delicious as that, the salads are really nice dressed with lemon and extra virgnin olive oil.\n",
      "Ground Truth Aspects: ['salads']\n",
      "Predicted Aspects: ['lamb chop', 'salads']\n",
      "--------------------------------------------------\n",
      "Sentence: Drawbacks: service is slow and they don't toast!\n",
      "Ground Truth Aspects: ['service']\n",
      "Predicted Aspects: ['service']\n",
      "--------------------------------------------------\n",
      "Sentence: The prices were fantastic.\n",
      "Ground Truth Aspects: ['prices']\n",
      "Predicted Aspects: ['prices']\n",
      "--------------------------------------------------\n",
      "Sentence: The food is terrible and overall, I would have to say avoid at all costs.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['food']\n",
      "--------------------------------------------------\n",
      "Sentence: The food is prepared quickly and efficiently.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['food']\n",
      "--------------------------------------------------\n",
      "Sentence: The food is fresh, delicious, and reasonably priced.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['food']\n",
      "--------------------------------------------------\n",
      "Sentence: The food is fresh, delicious, and reasonably priced.\n",
      "Ground Truth Aspects: ['priced']\n",
      "Predicted Aspects: ['food']\n",
      "--------------------------------------------------\n",
      "Sentence: As we were leaving, the couple standing by the door said to another waiter, we're not in a hurry.\n",
      "Ground Truth Aspects: ['waiter']\n",
      "Predicted Aspects: []\n",
      "--------------------------------------------------\n",
      "Sentence: The outdoor atmosphere of sitting on the sidewalk watching the world go by 50 feet away on 6th avenue on a cool evening was wonderful.\n",
      "Ground Truth Aspects: ['outdoor atmosphere']\n",
      "Predicted Aspects: ['outdoor']\n",
      "--------------------------------------------------\n",
      "Sentence: A large is $20, and toppings are about $3 each.\n",
      "Ground Truth Aspects: ['toppings']\n",
      "Predicted Aspects: ['large', 'toppings']\n",
      "--------------------------------------------------\n",
      "Sentence: The spicy tuna and salmon are the best we've ever had.\n",
      "Ground Truth Aspects: ['spicy tuna']\n",
      "Predicted Aspects: ['spicy tuna', 'salmon']\n",
      "--------------------------------------------------\n",
      "Sentence: The spicy tuna and salmon are the best we've ever had.\n",
      "Ground Truth Aspects: ['salmon']\n",
      "Predicted Aspects: ['spicy tuna', 'salmon']\n",
      "--------------------------------------------------\n",
      "Sentence: The food was very good, a great deal, and the place its self was great.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['food', 'place']\n",
      "--------------------------------------------------\n",
      "Sentence: The food was very good, a great deal, and the place its self was great.\n",
      "Ground Truth Aspects: ['place']\n",
      "Predicted Aspects: ['food', 'place']\n",
      "--------------------------------------------------\n",
      "Sentence: The food is usually good but it certainly isn't a relaxing place to go.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['food']\n",
      "--------------------------------------------------\n",
      "Sentence: The food is usually good but it certainly isn't a relaxing place to go.\n",
      "Ground Truth Aspects: ['place']\n",
      "Predicted Aspects: ['food']\n",
      "--------------------------------------------------\n",
      "Sentence: After dinner, take your date to the HUGE dance floor, probably one of the biggest you'll see in NY.\n",
      "Ground Truth Aspects: ['dinner']\n",
      "Predicted Aspects: ['dance']\n",
      "--------------------------------------------------\n",
      "Sentence: After dinner, take your date to the HUGE dance floor, probably one of the biggest you'll see in NY.\n",
      "Ground Truth Aspects: ['dance floor']\n",
      "Predicted Aspects: ['dance']\n",
      "--------------------------------------------------\n",
      "Sentence: The server was really cool and served us our food and drinks with a smile.\n",
      "Ground Truth Aspects: ['server']\n",
      "Predicted Aspects: ['server', 'food', 'drinks']\n",
      "--------------------------------------------------\n",
      "Sentence: The server was really cool and served us our food and drinks with a smile.\n",
      "Ground Truth Aspects: ['served']\n",
      "Predicted Aspects: ['server', 'food', 'drinks']\n",
      "--------------------------------------------------\n",
      "Sentence: The server was really cool and served us our food and drinks with a smile.\n",
      "Ground Truth Aspects: ['food']\n",
      "Predicted Aspects: ['server', 'food', 'drinks']\n",
      "--------------------------------------------------\n",
      "Sentence: The server was really cool and served us our food and drinks with a smile.\n",
      "Ground Truth Aspects: ['drinks']\n",
      "Predicted Aspects: ['server', 'food', 'drinks']\n",
      "--------------------------------------------------\n",
      "Sentence: The dishes offered were unique, very tasty and fresh from the lamb sausages, sardines with biscuits, large whole shrimp to the amazing pistachio ice cream (the best and freshest I've ever had).\n",
      "Ground Truth Aspects: ['dishes']\n",
      "Predicted Aspects: ['dishes', 'pistachio ice cream']\n",
      "--------------------------------------------------\n",
      "Sentence: The dishes offered were unique, very tasty and fresh from the lamb sausages, sardines with biscuits, large whole shrimp to the amazing pistachio ice cream (the best and freshest I've ever had).\n",
      "Ground Truth Aspects: ['lamb sausages']\n",
      "Predicted Aspects: ['dishes', 'pistachio ice cream']\n",
      "--------------------------------------------------\n",
      "Sentence: The dishes offered were unique, very tasty and fresh from the lamb sausages, sardines with biscuits, large whole shrimp to the amazing pistachio ice cream (the best and freshest I've ever had).\n",
      "Ground Truth Aspects: ['sardines with biscuits']\n",
      "Predicted Aspects: ['dishes', 'pistachio ice cream']\n",
      "--------------------------------------------------\n",
      "Sentence: The dishes offered were unique, very tasty and fresh from the lamb sausages, sardines with biscuits, large whole shrimp to the amazing pistachio ice cream (the best and freshest I've ever had).\n",
      "Ground Truth Aspects: ['large whole shrimp']\n",
      "Predicted Aspects: ['dishes', 'pistachio ice cream']\n",
      "--------------------------------------------------\n",
      "Sentence: The dishes offered were unique, very tasty and fresh from the lamb sausages, sardines with biscuits, large whole shrimp to the amazing pistachio ice cream (the best and freshest I've ever had).\n",
      "Ground Truth Aspects: ['pistachio ice cream']\n",
      "Predicted Aspects: ['dishes', 'pistachio ice cream']\n",
      "--------------------------------------------------\n",
      "Sentence: Went there for an office lunch.\n",
      "Ground Truth Aspects: ['office lunch']\n",
      "Predicted Aspects: []\n",
      "--------------------------------------------------\n",
      "Sentence: We've only eaten in the restaurant once, but we have ordered many times for dinner.\n",
      "Ground Truth Aspects: ['dinner']\n",
      "Predicted Aspects: []\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "id2label = {0: 'O', 1: 'B-ASP', 2: 'I-ASP'}\n",
    "\n",
    "def predict_aspects(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True)\n",
    "    inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=2)[0].cpu().numpy()\n",
    "    \n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    aspect_terms = []\n",
    "    current_aspect = []\n",
    "    \n",
    "    # Lặp qua từng token và nhãn tương ứng\n",
    "    for idx, pred in enumerate(predictions[1:len(tokens)+1]):  # Bỏ CLS token ở đầu và SEP token ở cuối\n",
    "        label = id2label[pred]\n",
    "        token = tokens[idx]\n",
    "        \n",
    "        if label == 'B-ASP':\n",
    "            if current_aspect:\n",
    "                aspect_terms.append(tokenizer.convert_tokens_to_string(current_aspect))\n",
    "                current_aspect = []\n",
    "            current_aspect = [token]\n",
    "        elif label == 'I-ASP' and current_aspect:\n",
    "            current_aspect.append(token)\n",
    "        else:\n",
    "            if current_aspect:\n",
    "                aspect_terms.append(tokenizer.convert_tokens_to_string(current_aspect))\n",
    "                current_aspect = []\n",
    "    if current_aspect:\n",
    "        aspect_terms.append(tokenizer.convert_tokens_to_string(current_aspect))\n",
    "    \n",
    "    # Loại bỏ ## và trim space\n",
    "    aspect_terms = [term.replace('##', '').strip() for term in aspect_terms]\n",
    "    return aspect_terms\n",
    "\n",
    "# Đọc file test CSV\n",
    "test_df = pd.read_csv('restaurants-trial.csv')\n",
    "\n",
    "# Test và in kết quả\n",
    "for idx, row in test_df.iterrows():\n",
    "    sentence = row['Sentence']\n",
    "    true_aspects = row['Aspect Term'].split(';')  # Giả sử các aspect term cách nhau bằng dấu ;\n",
    "    pred_aspects = predict_aspects(sentence)\n",
    "    \n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Ground Truth Aspects: {true_aspects}\")\n",
    "    print(f\"Predicted Aspects: {pred_aspects}\")\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "355efe16-ba14-4d58-87d7-aa45dec52438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The battery life is amazing but the screen is too dim.\n",
      "Extracted Aspects: ['battery life', 'screen']\n"
     ]
    }
   ],
   "source": [
    "def extract_aspect_terms(sentence):\n",
    "    encoding = tokenizer(sentence, return_offsets_mapping=True, return_tensors=\"pt\", truncation=True)\n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "    offsets = encoding[\"offset_mapping\"][0]  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits  \n",
    "    predictions = torch.argmax(logits, dim=-1)[0].cpu().numpy()  \n",
    "\n",
    "    id2label = {0: 'O', 1: 'B-ASP', 2: 'I-ASP'}\n",
    "\n",
    "    aspect_terms = []\n",
    "    current_aspect_tokens = []\n",
    "    for idx, pred_id in enumerate(predictions):\n",
    "        label = id2label.get(pred_id, 'O')\n",
    "        token = tokenizer.convert_ids_to_tokens(int(input_ids[0][idx]))\n",
    "        \n",
    "        if label == 'B-ASP':\n",
    "            if current_aspect_tokens:\n",
    "                aspect = tokenizer.convert_tokens_to_string(current_aspect_tokens)\n",
    "                aspect_terms.append(aspect.strip())\n",
    "                current_aspect_tokens = []\n",
    "            current_aspect_tokens = [token]\n",
    "        elif label == 'I-ASP' and current_aspect_tokens:\n",
    "            current_aspect_tokens.append(token)\n",
    "        else:\n",
    "            if current_aspect_tokens:\n",
    "                aspect = tokenizer.convert_tokens_to_string(current_aspect_tokens)\n",
    "                aspect_terms.append(aspect.strip())\n",
    "                current_aspect_tokens = []\n",
    "\n",
    "    if current_aspect_tokens:\n",
    "        aspect = tokenizer.convert_tokens_to_string(current_aspect_tokens)\n",
    "        aspect_terms.append(aspect.strip())\n",
    "\n",
    "    aspect_terms = list(set(aspect_terms))\n",
    "\n",
    "    return aspect_terms\n",
    "\n",
    "# Test\n",
    "test_sentence = \"The battery life is amazing but the screen is too dim.\"\n",
    "aspect_terms = extract_aspect_terms(test_sentence)\n",
    "print(\"Sentence:\", test_sentence)\n",
    "print(\"Extracted Aspects:\", aspect_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b88ada0c-456f-4981-9adc-99cd225a4b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sentence))      \n",
    "print(type(aspect_terms))   \n",
    "\n",
    "if isinstance(aspect_terms, list):\n",
    "    aspect_term = \" \".join(aspect_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45c3ade5-cb4c-43cc-9fc4-16b7b521353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for aspect in aspect_terms:\n",
    "    if not isinstance(aspect, str):\n",
    "        aspect = \" \".join(aspect)\n",
    "    inputs = tokenizer(sentence, aspect, return_tensors='pt', truncation=True, padding=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb4f66b6-00f8-4fe4-a0b0-4bcaf2d1fcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sentence))      \n",
    "print(type(aspect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1f04a6a-8e19-4b00-8b4a-31543622c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c1de77e-ce81-4330-93ef-0e09649a83a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Aspect Term</th>\n",
       "      <th>polarity</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2339</td>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>cord</td>\n",
       "      <td>neutral</td>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2339</td>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>battery life</td>\n",
       "      <td>positive</td>\n",
       "      <td>74</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1316</td>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>service center</td>\n",
       "      <td>negative</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1316</td>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>\"sales\" team</td>\n",
       "      <td>negative</td>\n",
       "      <td>109</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1316</td>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>tech guy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                           Sentence     Aspect Term  \\\n",
       "0  2339  I charge it at night and skip taking the cord ...            cord   \n",
       "1  2339  I charge it at night and skip taking the cord ...    battery life   \n",
       "2  1316  The tech guy then said the service center does...  service center   \n",
       "3  1316  The tech guy then said the service center does...    \"sales\" team   \n",
       "4  1316  The tech guy then said the service center does...        tech guy   \n",
       "\n",
       "   polarity  from   to  \n",
       "0   neutral    41   45  \n",
       "1  positive    74   86  \n",
       "2  negative    27   41  \n",
       "3  negative   109  121  \n",
       "4   neutral     4   12  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b06dfb2-2be0-462f-9fb3-2787fac86895",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['Sentence', 'Aspect Term', 'polarity']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d453cbec-a40a-4ba4-9803-f1c8852869a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Sentence': 'I charge it at night and skip taking the cord with me because of the good battery life.', 'Aspect Term': 'cord', 'polarity': 'neutral'}, {'Sentence': 'I charge it at night and skip taking the cord with me because of the good battery life.', 'Aspect Term': 'battery life', 'polarity': 'positive'}, {'Sentence': 'The tech guy then said the service center does not do 1-to-1 exchange and I have to direct my concern to the \"sales\" team, which is the retail shop which I bought my netbook from.', 'Aspect Term': 'service center', 'polarity': 'negative'}, {'Sentence': 'The tech guy then said the service center does not do 1-to-1 exchange and I have to direct my concern to the \"sales\" team, which is the retail shop which I bought my netbook from.', 'Aspect Term': '\"sales\" team', 'polarity': 'negative'}, {'Sentence': 'The tech guy then said the service center does not do 1-to-1 exchange and I have to direct my concern to the \"sales\" team, which is the retail shop which I bought my netbook from.', 'Aspect Term': 'tech guy', 'polarity': 'neutral'}]\n"
     ]
    }
   ],
   "source": [
    "print(data[:5])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0c06d90-e1f0-449e-b6a0-cd5eb16ba13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AspectSentimentDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.label2id = {'positive': 0,'negative': 1,'neutral': 2,'conflict': 3}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        sentence = item['Sentence']\n",
    "        aspect = item['Aspect Term']\n",
    "        sentiment = item['polarity']\n",
    "        \n",
    "        inputs = self.tokenizer(\n",
    "            sentence,\n",
    "            aspect,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        label = self.label2id[sentiment]\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e803f7a3-0aef-4eb2-9af1-a58adc969ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9acf0b52-a20f-43e3-89d0-018f1e7074dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█| 379/379 [1:21:27<00:00, 12.89s/it, accuracy=0.6895, loss=0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed, average loss: 0.7948, accuracy: 0.6895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "dataset = AspectSentimentDataset(data, tokenizer, max_len=128)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "model.train()\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    loop = tqdm(loader, desc=f\"Epoch {epoch+1}\")\n",
    "    for batch in loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits  \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct = (preds == labels).sum().item()\n",
    "        total_correct += correct\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        acc = total_correct / total_samples\n",
    "\n",
    "        loop.set_postfix(loss=f\"{loss.item():.4f}\", accuracy=f\"{acc:.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1} completed, average loss: {total_loss/len(loader):.4f}, accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0bb2b34f-44d5-4465-93b4-8f774896fef9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 3 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m pred_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# shape [batch_size]\u001b[39;00m\n\u001b[0;32m     24\u001b[0m id2label \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m3\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconflict\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m---> 25\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m [id2label[i\u001b[38;5;241m.\u001b[39mitem()] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m pred_ids]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent, asp, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sentences, aspects, pred_labels):\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[58], line 25\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     22\u001b[0m pred_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# shape [batch_size]\u001b[39;00m\n\u001b[0;32m     24\u001b[0m id2label \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m3\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconflict\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m---> 25\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m [id2label[i\u001b[38;5;241m.\u001b[39mitem()] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m pred_ids]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent, asp, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sentences, aspects, pred_labels):\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: a Tensor with 3 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"The battery life of this phone is amazing.\",\n",
    "    \"The screen is too dim to use outside.\",\n",
    "    \"The phone comes in black and white colors.\"\n",
    "]\n",
    "\n",
    "aspects = [\n",
    "    \"battery life\",\n",
    "    \"screen\",\n",
    "    \"color\"\n",
    "]\n",
    "\n",
    "inputs = tokenizer(\n",
    "    [f\"{s} [SEP] {a}\" for s, a in zip(sentences, aspects)],\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    padding=True\n",
    ").to(device)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "pred_ids = torch.argmax(logits, dim=1)  # shape [batch_size]\n",
    "\n",
    "id2label = {0: 'positive', 1: 'negative', 2: 'neutral', 3: 'conflict'}\n",
    "pred_labels = [id2label[i.item()] for i in pred_ids]\n",
    "\n",
    "for sent, asp, label in zip(sentences, aspects, pred_labels):\n",
    "    print(f\"Sentence: {sent}\")\n",
    "    print(f\"Aspect: {asp}\")\n",
    "    print(f\"Predicted sentiment: {label}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b489beb2-e2fe-413a-84ce-83341c21431a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_ids shape: torch.Size([3, 3])\n",
      "pred_ids[0]: tensor([7, 2, 3]), shape: torch.Size([3]), type: <class 'torch.Tensor'>\n",
      "pred_ids[1]: tensor([3, 2, 9]), shape: torch.Size([3]), type: <class 'torch.Tensor'>\n",
      "pred_ids[2]: tensor([ 4, 11,  9]), shape: torch.Size([3]), type: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"pred_ids shape: {pred_ids.shape}\")\n",
    "for i, val in enumerate(pred_ids):\n",
    "    print(f\"pred_ids[{i}]: {val}, shape: {val.shape}, type: {type(val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b125f026-1141-4f6d-a7da-4d43760872fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: torch.Size([3, 14, 3])\n",
      "logits sample: tensor([[ 3.7309, -1.9212, -2.0670],\n",
      "        [ 5.2071, -2.8100, -2.0040],\n",
      "        [ 0.2058,  2.5244, -2.0840],\n",
      "        [ 0.2199, -1.9082,  2.2136],\n",
      "        [ 3.8750, -2.7296, -1.1596],\n",
      "        [ 4.7836, -1.9739, -1.9726],\n",
      "        [ 3.1721, -0.8119, -1.7712],\n",
      "        [ 5.3619, -2.6456, -2.3874],\n",
      "        [ 5.3613, -2.5043, -2.3808],\n",
      "        [ 1.7437, -0.5577, -0.7162],\n",
      "        [ 2.9965, -1.4894, -0.8913],\n",
      "        [ 0.8897,  2.0194, -2.4748],\n",
      "        [ 1.4126, -2.3025,  1.0760],\n",
      "        [ 2.9953, -1.4891, -0.8906]], grad_fn=<SelectBackward0>)\n",
      "argmax dim=1 shape: torch.Size([3, 3])\n",
      "argmax dim=2 shape: torch.Size([3, 14])\n"
     ]
    }
   ],
   "source": [
    "print(f\"logits shape: {logits.shape}\")\n",
    "print(f\"logits sample: {logits[0]}\")\n",
    "\n",
    "# Kiểm tra giá trị argmax ở các chiều\n",
    "pred_ids_dim1 = torch.argmax(logits, dim=1)\n",
    "print(f\"argmax dim=1 shape: {pred_ids_dim1.shape}\")\n",
    "\n",
    "pred_ids_dim2 = torch.argmax(logits, dim=2)\n",
    "print(f\"argmax dim=2 shape: {pred_ids_dim2.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6e83e13d-97b8-4679-9737-167f9e172bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: torch.Size([3, 4])\n",
      "logits: tensor([[ 0.5470,  0.5108,  1.1177, -1.6352],\n",
      "        [ 0.2685, -0.3193,  2.1372, -1.9222],\n",
      "        [-0.2163,  2.4923,  0.1604, -1.0454]], grad_fn=<AddmmBackward0>)\n",
      "pred_ids shape: torch.Size([3])\n",
      "pred_ids: tensor([2, 2, 1])\n",
      "pred_ids[0]: 2, shape: torch.Size([]), type: <class 'torch.Tensor'>\n",
      "pred_ids[0] as scalar: 2\n",
      "pred_ids[1]: 2, shape: torch.Size([]), type: <class 'torch.Tensor'>\n",
      "pred_ids[1] as scalar: 2\n",
      "pred_ids[2]: 1, shape: torch.Size([]), type: <class 'torch.Tensor'>\n",
      "pred_ids[2] as scalar: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"logits shape: {logits.shape}\")   # xem shape logits\n",
    "print(f\"logits: {logits}\")\n",
    "\n",
    "pred_ids = torch.argmax(logits, dim=1)\n",
    "print(f\"pred_ids shape: {pred_ids.shape}\") \n",
    "print(f\"pred_ids: {pred_ids}\")\n",
    "\n",
    "for i, val in enumerate(pred_ids):\n",
    "    print(f\"pred_ids[{i}]: {val}, shape: {getattr(val, 'shape', None)}, type: {type(val)}\")\n",
    "    try:\n",
    "        scalar = val.item()\n",
    "        print(f\"pred_ids[{i}] as scalar: {scalar}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting pred_ids[{i}] to scalar:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4b3131c-ffb0-4ed8-ba5c-172f474c33be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./model2\\\\tokenizer_config.json',\n",
       " './model2\\\\special_tokens_map.json',\n",
       " './model2\\\\vocab.txt',\n",
       " './model2\\\\added_tokens.json',\n",
       " './model2\\\\tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Giả sử bạn đã huấn luyện xong Model 2 (model và tokenizer là biến bạn đang dùng)\n",
    "save_path = \"./model2\"\n",
    "\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6241c845-f0fe-4473-a74e-593be0919e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00c92b630e48460cbc24d2344d54849b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "06d2640269e045e39cfac2b54b7d6286": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "10fd7fd6f4fb4f64a2db45b06067636e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_14fa94c1247f40268e46b4e5d8baefb1",
       "style": "IPY_MODEL_4fa954ea105941e39898a70fcff1ea09",
       "value": " 1.03k/1.03k [00:00&lt;00:00, 97.5kB/s]"
      }
     },
     "11091e90e6c34df28722155f564eb2db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9ef07da4ee8d4a67979e15c6d84d8872",
       "style": "IPY_MODEL_bc63f349dc6243b0aaa5e551b0476bbd",
       "value": " 156/156 [00:00&lt;00:00, 17.4kB/s]"
      }
     },
     "1442c06dc76a48d5b2d0045ebd3f198b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "14fa94c1247f40268e46b4e5d8baefb1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "17e58ed8ab3140f09156e5f5bedf86fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "17eb3ebf4e934177ae56b8af389aa5b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_b00fb7ce753f4493af8652716aa24e8c",
       "max": 2464616,
       "style": "IPY_MODEL_a60e5495cb8844a29d2ab0224339c166",
       "value": 2464616
      }
     },
     "1d011f81af1246dfa25f3dd066b72bde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1dedbdc6f3dc4966bdfc376e1ccc595b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1f21e3a5601c4635b97e51507cc0d567": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "224fc2f804d64b33968d3b7730350603": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d92262a4085f438d8188bc0a0c941f32",
       "style": "IPY_MODEL_d513d8f8d6b34972bbda5eea0bd349e6",
       "value": "special_tokens_map.json: 100%"
      }
     },
     "2774cb618dac4636ae85a859bacb6ddb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "27aef84aa2614aa1b43bbffa192ffc5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2e590555dfa5472a8b9b89998c748a0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "300c51a1ae7341d78ae2d3c84694fa47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "352d18215a47417499d06f2b63c28934": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "35e06aba063d4e3e8cf0d6c28b961aaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_620633a7192d4ee88d456a9910f966bc",
        "IPY_MODEL_618eb216a09345c98f9f4ae32f213fb3",
        "IPY_MODEL_874e023902c64595be3c143efa2aed5f"
       ],
       "layout": "IPY_MODEL_ec5a0dbf363947f98cce98fa44aa407b"
      }
     },
     "37016fb03f714a04a6c2192d2f4ca25a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7fef5327bfd4489f93cc96d6737ea461",
       "style": "IPY_MODEL_bfa92d39caf247e1b685ec1cd4e33629",
       "value": "spm.model: 100%"
      }
     },
     "3815ef70b600442588f91fef0dc8f4c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_4bae1c2655844aa48903800a41f9c581",
       "max": 1032,
       "style": "IPY_MODEL_1f21e3a5601c4635b97e51507cc0d567",
       "value": 1032
      }
     },
     "3b1b26800db646e795742bfe3cddf70f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_927a60a421c24f0bbe59b1667611d77a",
        "IPY_MODEL_93481cc4c62347d58833f5528b3e03ca",
        "IPY_MODEL_725cfcac6be842679fae23ff42468e7e"
       ],
       "layout": "IPY_MODEL_96b16cffb1c349faadecd6d558ed1b69"
      }
     },
     "4009867442164ad7a036299047c708e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4077108b9c1d462999b54b673a8214d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4bae1c2655844aa48903800a41f9c581": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4fa954ea105941e39898a70fcff1ea09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "618eb216a09345c98f9f4ae32f213fb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_d6895d74b49548b48d6440c3ad05deaf",
       "max": 372,
       "style": "IPY_MODEL_2e590555dfa5472a8b9b89998c748a0d",
       "value": 372
      }
     },
     "620633a7192d4ee88d456a9910f966bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1442c06dc76a48d5b2d0045ebd3f198b",
       "style": "IPY_MODEL_1dedbdc6f3dc4966bdfc376e1ccc595b",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "63ddf9ff5f1a4c4689e9dd81138e9a6a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "725cfcac6be842679fae23ff42468e7e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4077108b9c1d462999b54b673a8214d4",
       "style": "IPY_MODEL_17e58ed8ab3140f09156e5f5bedf86fc",
       "value": " 738M/738M [02:50&lt;00:00, 4.79MB/s]"
      }
     },
     "72a3399219f747e9b31571216eba378b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_98efacd32b6b43eda3f126a5de25e6fe",
       "style": "IPY_MODEL_300c51a1ae7341d78ae2d3c84694fa47",
       "value": " 18.0/18.0 [00:00&lt;00:00, 1.89kB/s]"
      }
     },
     "74b33bee6d764335b59e3b0fab779734": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7e4c727a53b7420ca5fadd77492a2e12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_352d18215a47417499d06f2b63c28934",
       "max": 18,
       "style": "IPY_MODEL_27aef84aa2614aa1b43bbffa192ffc5d",
       "value": 18
      }
     },
     "7fef5327bfd4489f93cc96d6737ea461": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "874e023902c64595be3c143efa2aed5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fa6ffbc6d13b4feaa0985cf5f0c69950",
       "style": "IPY_MODEL_e7f3174ddb8e439cb0d94ad5722be417",
       "value": " 372/372 [00:00&lt;00:00, 58.3kB/s]"
      }
     },
     "8d2c261bb65e4846bce8daa06e1c261d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a64b1db9785e45d7a640ae113e639f41",
        "IPY_MODEL_3815ef70b600442588f91fef0dc8f4c8",
        "IPY_MODEL_10fd7fd6f4fb4f64a2db45b06067636e"
       ],
       "layout": "IPY_MODEL_d3244bed659847aea71a883acf8bc97c"
      }
     },
     "8e22e76cfbfa4560a3ecefa6410f6752": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_37016fb03f714a04a6c2192d2f4ca25a",
        "IPY_MODEL_17eb3ebf4e934177ae56b8af389aa5b9",
        "IPY_MODEL_e1a5b37c13984aa4add9057e76324ee1"
       ],
       "layout": "IPY_MODEL_4009867442164ad7a036299047c708e9"
      }
     },
     "927a60a421c24f0bbe59b1667611d77a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2774cb618dac4636ae85a859bacb6ddb",
       "style": "IPY_MODEL_1d011f81af1246dfa25f3dd066b72bde",
       "value": "model.safetensors: 100%"
      }
     },
     "93481cc4c62347d58833f5528b3e03ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_d966a9fec0c3469a904c432c82e1ef9a",
       "max": 737726548,
       "style": "IPY_MODEL_9c5a779ec9db4fa992a733b77773a1cf",
       "value": 737726548
      }
     },
     "96b16cffb1c349faadecd6d558ed1b69": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "98efacd32b6b43eda3f126a5de25e6fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9c5a779ec9db4fa992a733b77773a1cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9ef07da4ee8d4a67979e15c6d84d8872": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a4d32e0797874550a91f04b1676f0b07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a574006d7107445c96d0e637f6ea8a45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_224fc2f804d64b33968d3b7730350603",
        "IPY_MODEL_fc4555e2e25a42458e544a3f78ca811e",
        "IPY_MODEL_11091e90e6c34df28722155f564eb2db"
       ],
       "layout": "IPY_MODEL_f78ea73affe144a186189d50f52eb17e"
      }
     },
     "a60e5495cb8844a29d2ab0224339c166": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a64b1db9785e45d7a640ae113e639f41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a4d32e0797874550a91f04b1676f0b07",
       "style": "IPY_MODEL_06d2640269e045e39cfac2b54b7d6286",
       "value": "config.json: 100%"
      }
     },
     "b00fb7ce753f4493af8652716aa24e8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b513986e440c4257b4658e8ea6fc4f86": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bc63f349dc6243b0aaa5e551b0476bbd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bfa92d39caf247e1b685ec1cd4e33629": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c361d78495254a008470cfc98f3fe1df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d27d1bb63dd34da8b7789aff606439f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d3244bed659847aea71a883acf8bc97c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d513d8f8d6b34972bbda5eea0bd349e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d6895d74b49548b48d6440c3ad05deaf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d92262a4085f438d8188bc0a0c941f32": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d966a9fec0c3469a904c432c82e1ef9a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e1a5b37c13984aa4add9057e76324ee1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b513986e440c4257b4658e8ea6fc4f86",
       "style": "IPY_MODEL_74b33bee6d764335b59e3b0fab779734",
       "value": " 2.46M/2.46M [00:00&lt;00:00, 6.87MB/s]"
      }
     },
     "e7f3174ddb8e439cb0d94ad5722be417": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e83986e176344646b71ac4444c7d3cf8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ec5a0dbf363947f98cce98fa44aa407b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ecf396f00eb542d8a1c39bcbe4804790": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f08efa52811543249ae70117dba0eb43",
        "IPY_MODEL_7e4c727a53b7420ca5fadd77492a2e12",
        "IPY_MODEL_72a3399219f747e9b31571216eba378b"
       ],
       "layout": "IPY_MODEL_c361d78495254a008470cfc98f3fe1df"
      }
     },
     "f08efa52811543249ae70117dba0eb43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_63ddf9ff5f1a4c4689e9dd81138e9a6a",
       "style": "IPY_MODEL_00c92b630e48460cbc24d2344d54849b",
       "value": "added_tokens.json: 100%"
      }
     },
     "f78ea73affe144a186189d50f52eb17e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fa6ffbc6d13b4feaa0985cf5f0c69950": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fc4555e2e25a42458e544a3f78ca811e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_d27d1bb63dd34da8b7789aff606439f7",
       "max": 156,
       "style": "IPY_MODEL_e83986e176344646b71ac4444c7d3cf8",
       "value": 156
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
